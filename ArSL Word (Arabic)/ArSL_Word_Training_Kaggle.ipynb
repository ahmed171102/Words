{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd93d542",
   "metadata": {},
   "source": [
    "# ArSL Word Training — Kaggle GPU Optimized (KArSL + MediaPipe + BiLSTM)\n",
    "\n",
    "**Full-parameter Kaggle notebook** for training a word-level Arabic sign language recognition model using KArSL data.\n",
    "\n",
    "### Key Features:\n",
    "\n",
    "- **Two-hand detection** (126 features = 2 x 21 landmarks x 3 coords) — captures signs requiring both hands\n",
    "- **GPU-optimized** for Kaggle T4/P100 GPUs\n",
    "- **Full training parameters** — no shortcuts, full augmentation pipeline\n",
    "- **tf.data pipeline** with prefetch, shuffle & augmentation\n",
    "- **CuDNN-compatible LSTM** — hardware-accelerated RNN\n",
    "- **Temporal Attention** — learns which frames matter most\n",
    "- **Label smoothing + gradient clipping** — robust training\n",
    "- **Comprehensive evaluation** — confusion matrix, per-class F1, category breakdown\n",
    "- **Supports pre-extracted keypoints** (.npy/.csv) or raw video (.mp4)\n",
    "\n",
    "### Output Artifacts:\n",
    "\n",
    "- `arsl_word_sequences_2hand.npz` — Extracted two-hand sequences\n",
    "- `arsl_word_lstm_model_best.h5` — Best model checkpoint\n",
    "- `arsl_word_lstm_model_final.h5` — Final model\n",
    "- `arsl_word_classes.csv` — Class mapping\n",
    "\n",
    "### Kaggle Setup:\n",
    "\n",
    "1. Upload `shared_word_vocabulary.csv` as a dataset\n",
    "2. Upload KArSL-502 dataset (from [Kaggle](https://www.kaggle.com/datasets/yousefelkilany/karsl-502))\n",
    "3. Enable GPU accelerator in notebook settings\n",
    "4. Run all cells in order\n",
    "\n",
    "### Architecture: Same as English ASL Word Model\n",
    "\n",
    "Both Arabic and English word models share identical BiLSTM + TemporalAttention architecture and `shared_word_vocabulary.csv`, enabling bilingual translation in the combined system.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19912128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# CELL 1: INSTALL & IMPORTS\n",
    "# ===============================\n",
    "import subprocess\n",
    "import sys\n",
    "try:\n",
    "    import mediapipe\n",
    "except ImportError:\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'mediapipe', '-q'])\n",
    "\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import mediapipe as mp_lib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, LSTM, Bidirectional, Dense,\n",
    "    Dropout, BatchNormalization\n",
    ")\n",
    "from tensorflow.keras.callbacks import (\n",
    "    ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    ")\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import mixed_precision\n",
    "from tqdm import tqdm\n",
    "\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "print('=' * 60)\n",
    "print('All libraries imported')\n",
    "print(f'TensorFlow : {tf.__version__}')\n",
    "print(f'NumPy      : {np.__version__}')\n",
    "print(f'Pandas     : {pd.__version__}')\n",
    "print(f'OpenCV     : {cv2.__version__}')\n",
    "print('=' * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df612b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CELL 2: GPU DETECTION & CONFIGURATION\n",
    "# ============================================\n",
    "print('=' * 60)\n",
    "print('GPU DETECTION & CONFIGURATION')\n",
    "print('=' * 60)\n",
    "print(f'\\nTensorFlow version: {tf.__version__}')\n",
    "print(f'Built with CUDA  : {tf.test.is_built_with_cuda()}')\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices()\n",
    "print(f'\\nAll Physical Devices: {physical_devices}')\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(f'\\nGPU Devices Found: {len(gpus)}')\n",
    "\n",
    "USE_GPU = False\n",
    "DEVICE = '/CPU:0'\n",
    "\n",
    "if gpus:\n",
    "    print('\\nGPU IS AVAILABLE!')\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f'   Memory growth enabled for {len(gpus)} GPU(s)')\n",
    "\n",
    "        tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "        USE_GPU = True\n",
    "        DEVICE = '/GPU:0'\n",
    "        print(f'   Using GPU: {gpus[0].name}')\n",
    "\n",
    "        try:\n",
    "            details = tf.config.experimental.get_device_details(gpus[0])\n",
    "            if 'device_name' in details:\n",
    "                print(f'   Device Name       : {details[\"device_name\"]}')\n",
    "            if 'compute_capability' in details:\n",
    "                print(f'   Compute Capability: {details[\"compute_capability\"]}')\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    except RuntimeError as e:\n",
    "        print(f'   GPU config error: {e}')\n",
    "else:\n",
    "    print('\\nNo GPU detected — training on CPU (will be much slower)')\n",
    "\n",
    "# Mixed precision — keep OFF for LSTM to avoid NaN\n",
    "ENABLE_MIXED_PRECISION = False\n",
    "\n",
    "if USE_GPU and ENABLE_MIXED_PRECISION:\n",
    "    try:\n",
    "        policy = mixed_precision.Policy('mixed_float16')\n",
    "        mixed_precision.set_global_policy(policy)\n",
    "        print(f'\\nMixed precision enabled: {policy.name}')\n",
    "    except Exception as e:\n",
    "        print(f'\\nMixed precision not enabled: {e}')\n",
    "else:\n",
    "    mixed_precision.set_global_policy('float32')\n",
    "    print(f'\\nUsing float32 precision (stable for LSTM)')\n",
    "\n",
    "# GPU verification test\n",
    "if USE_GPU:\n",
    "    print('\\nGPU Verification Test...')\n",
    "    try:\n",
    "        with tf.device('/GPU:0'):\n",
    "            a = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
    "            b = tf.constant([[5.0, 6.0], [7.0, 8.0]])\n",
    "            c = tf.matmul(a, b)\n",
    "        print(f'   GPU computation successful: {c.device}')\n",
    "    except Exception as e:\n",
    "        print(f'   GPU test failed: {e}')\n",
    "        USE_GPU = False\n",
    "        DEVICE = '/CPU:0'\n",
    "\n",
    "print(f'\\nConfiguration complete. Using device: {DEVICE}')\n",
    "print('=' * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbd4ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# CELL 3: CONFIGURATION / PATHS\n",
    "# ===============================\n",
    "# Kaggle paths — update dataset names to match your uploads\n",
    "\n",
    "IS_KAGGLE = os.path.exists('/kaggle')\n",
    "\n",
    "if IS_KAGGLE:\n",
    "    # ===== KAGGLE PATHS =====\n",
    "    KAGGLE_INPUT = Path('/kaggle/input')\n",
    "    KAGGLE_OUTPUT = Path('/kaggle/working')\n",
    "\n",
    "    # Update these dataset names to match YOUR Kaggle dataset uploads:\n",
    "    KARSL_DATASET = KAGGLE_INPUT / 'karsl-502'              # KArSL-502 dataset\n",
    "    VOCAB_DATASET = KAGGLE_INPUT / 'slr-shared-vocabulary'  # shared_word_vocabulary.csv\n",
    "\n",
    "    SHARED_CSV = VOCAB_DATASET / 'shared_word_vocabulary.csv'\n",
    "    KARSL_ROOT = KARSL_DATASET  # root of extracted KArSL class folders\n",
    "    OUTPUT_DIR = KAGGLE_OUTPUT\n",
    "else:\n",
    "    # ===== LOCAL PATHS =====\n",
    "    PROJECT_ROOT = Path(r'E:/Term 9/Grad')\n",
    "    SLR_MAIN = PROJECT_ROOT / 'Main/Sign-Language-Recognition-System-main/SLR Main'\n",
    "    WORDS_ROOT = SLR_MAIN / 'Words'\n",
    "    SHARED_CSV = WORDS_ROOT / 'Shared/shared_word_vocabulary.csv'\n",
    "    KARSL_ROOT = WORDS_ROOT / 'Datasets/KArSL_502'\n",
    "    OUTPUT_DIR = WORDS_ROOT / 'ArSL Word (Arabic)'\n",
    "\n",
    "# ===== TWO-HAND SEQUENCE PARAMETERS =====\n",
    "SEQUENCE_LENGTH = 30        # frames per sample\n",
    "NUM_HANDS = 2               # detect both hands\n",
    "LANDMARKS_PER_HAND = 63     # 21 landmarks x 3 (x, y, z)\n",
    "NUM_FEATURES = NUM_HANDS * LANDMARKS_PER_HAND  # 126 features\n",
    "\n",
    "# ===== FULL TRAINING HYPERPARAMETERS =====\n",
    "BATCH_SIZE      = 64        # GPU batch size\n",
    "EPOCHS          = 150       # max epochs (early stopping will cut short)\n",
    "LEARNING_RATE   = 5e-4      # initial learning rate\n",
    "LSTM_UNITS_1    = 256       # BiLSTM layer 1 (larger for 126 features)\n",
    "LSTM_UNITS_2    = 128       # BiLSTM layer 2\n",
    "LSTM_UNITS_3    = 64        # LSTM layer 3\n",
    "DENSE_UNITS     = 256       # Dense head (larger for more capacity)\n",
    "DROPOUT_RATE    = 0.4       # dropout rate\n",
    "LABEL_SMOOTH    = 0.1       # label smoothing\n",
    "GRAD_CLIP_NORM  = 1.0       # gradient clipping\n",
    "L2_REG          = 1e-4      # L2 regularization\n",
    "TEST_SIZE       = 0.4       # val+test fraction -> 60/20/20\n",
    "\n",
    "# If True, load pre-extracted .npy/.csv keypoints (faster)\n",
    "# If False, extract from raw .mp4 videos using MediaPipe\n",
    "USE_PREEXTRACTED_KEYPOINTS = True\n",
    "\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True) if not IS_KAGGLE else None\n",
    "\n",
    "# Verify paths\n",
    "for name, path in [('Shared CSV', SHARED_CSV), ('KArSL root', KARSL_ROOT)]:\n",
    "    status = 'FOUND' if path.exists() else 'NOT FOUND'\n",
    "    print(f'{status} — {name}: {path}')\n",
    "\n",
    "print(f'\\nOutput dir     : {OUTPUT_DIR}')\n",
    "print(f'\\nSequence length : {SEQUENCE_LENGTH}')\n",
    "print(f'Hands           : {NUM_HANDS}')\n",
    "print(f'Features/frame  : {NUM_FEATURES}')\n",
    "print(f'Batch size      : {BATCH_SIZE}')\n",
    "print(f'Max epochs      : {EPOCHS}')\n",
    "print(f'Learning rate   : {LEARNING_RATE}')\n",
    "print(f'LSTM units      : {LSTM_UNITS_1}/{LSTM_UNITS_2}/{LSTM_UNITS_3}')\n",
    "print(f'Dense units     : {DENSE_UNITS}')\n",
    "print(f'Pre-extracted   : {USE_PREEXTRACTED_KEYPOINTS}')\n",
    "print(f'Running on      : {\"Kaggle\" if IS_KAGGLE else \"Local\"}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6307c81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# CELL 4: LOAD SHARED VOCABULARY\n",
    "# ===============================\n",
    "print('=' * 60)\n",
    "print('LOADING SHARED VOCABULARY')\n",
    "print('=' * 60)\n",
    "\n",
    "vocab_df = pd.read_csv(SHARED_CSV)\n",
    "vocab_df = vocab_df.dropna(subset=['karsl_class'])\n",
    "vocab_df['karsl_class'] = vocab_df['karsl_class'].astype(int)\n",
    "\n",
    "karsl_to_wordid = dict(zip(vocab_df['karsl_class'], vocab_df['word_id'].astype(int)))\n",
    "id_to_english = dict(zip(vocab_df['word_id'].astype(int), vocab_df['english']))\n",
    "id_to_arabic = dict(zip(vocab_df['word_id'].astype(int), vocab_df['arabic']))\n",
    "target_karsl_classes = sorted(karsl_to_wordid.keys())\n",
    "\n",
    "print(f'\\nMatched vocabulary : {len(target_karsl_classes)} Arabic words')\n",
    "print(f'Categories         : {vocab_df[\"category\"].nunique()} — {sorted(vocab_df[\"category\"].unique())}')\n",
    "print(f'Sample classes     : {target_karsl_classes[:10]}...')\n",
    "print(f'\\nSample words:')\n",
    "for _, row in vocab_df.head(10).iterrows():\n",
    "    print(f'   word_id={int(row[\"word_id\"]):3d} | {row[\"english\"]:15s} | {row[\"arabic\"]:10s} | karsl={int(row[\"karsl_class\"]):3d} | {row[\"category\"]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29050f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# CELL 5: HELPER FUNCTIONS (TWO-HAND)\n",
    "# ===============================\n",
    "\n",
    "def pad_or_sample(sequence, target_len=SEQUENCE_LENGTH, target_features=NUM_FEATURES):\n",
    "    \"\"\"Pad (short) or uniformly sample (long) a sequence to fixed shape.\"\"\"\n",
    "    arr = np.array(sequence, dtype=np.float32)\n",
    "    if arr.ndim != 2:\n",
    "        return None\n",
    "\n",
    "    # Adjust feature dimension\n",
    "    if arr.shape[1] > target_features:\n",
    "        arr = arr[:, :target_features]\n",
    "    elif arr.shape[1] < target_features:\n",
    "        pad_feat = np.zeros((arr.shape[0], target_features - arr.shape[1]), dtype=np.float32)\n",
    "        arr = np.concatenate([arr, pad_feat], axis=1)\n",
    "\n",
    "    # Adjust time dimension\n",
    "    if arr.shape[0] >= target_len:\n",
    "        idx = np.linspace(0, arr.shape[0] - 1, target_len, dtype=int)\n",
    "        arr = arr[idx]\n",
    "    else:\n",
    "        pad_time = np.zeros((target_len - arr.shape[0], target_features), dtype=np.float32)\n",
    "        arr = np.concatenate([arr, pad_time], axis=0)\n",
    "\n",
    "    return arr  # shape: (SEQUENCE_LENGTH, NUM_FEATURES)\n",
    "\n",
    "\n",
    "# MediaPipe for video extraction (used when USE_PREEXTRACTED_KEYPOINTS=False)\n",
    "mp_hands = mp_lib.solutions.hands\n",
    "\n",
    "def extract_from_video_2hand(video_path):\n",
    "    \"\"\"Extract two-hand MediaPipe landmarks from a video file.\n",
    "    Hands ordered consistently: Left first, Right second.\n",
    "    Missing hand is zero-padded.\"\"\"\n",
    "    hands = mp_hands.Hands(\n",
    "        static_image_mode=False,\n",
    "        max_num_hands=2,           # detect BOTH hands\n",
    "        min_detection_confidence=0.5,\n",
    "        min_tracking_confidence=0.5\n",
    "    )\n",
    "    cap = cv2.VideoCapture(str(video_path))\n",
    "    if not cap.isOpened():\n",
    "        hands.close()\n",
    "        return None\n",
    "\n",
    "    frames = []\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        result = hands.process(rgb)\n",
    "\n",
    "        left_vec = np.zeros(LANDMARKS_PER_HAND, dtype=np.float32)\n",
    "        right_vec = np.zeros(LANDMARKS_PER_HAND, dtype=np.float32)\n",
    "\n",
    "        if result.multi_hand_landmarks and result.multi_handedness:\n",
    "            for hand_lm, handedness in zip(result.multi_hand_landmarks, result.multi_handedness):\n",
    "                label = handedness.classification[0].label  # 'Left' or 'Right'\n",
    "                vec = np.array([[p.x, p.y, p.z] for p in hand_lm.landmark]).flatten()\n",
    "                if label == 'Left':\n",
    "                    left_vec = vec\n",
    "                else:\n",
    "                    right_vec = vec\n",
    "\n",
    "        frames.append(np.concatenate([left_vec, right_vec]))\n",
    "\n",
    "    cap.release()\n",
    "    hands.close()\n",
    "\n",
    "    if len(frames) == 0:\n",
    "        return None\n",
    "    return pad_or_sample(np.array(frames, dtype=np.float32))\n",
    "\n",
    "\n",
    "def adapt_preextracted_to_2hand(arr):\n",
    "    \"\"\"Convert pre-extracted 1-hand keypoints (63 features) to 2-hand format (126).\n",
    "    Places the data in the RIGHT hand slot (most signers are right-handed),\n",
    "    zero-pads the LEFT hand slot.\"\"\"\n",
    "    if arr.shape[1] == NUM_FEATURES:\n",
    "        return arr  # already 2-hand\n",
    "    elif arr.shape[1] == LANDMARKS_PER_HAND:\n",
    "        # 1-hand data -> put in right-hand slot, zero-pad left\n",
    "        left_pad = np.zeros((arr.shape[0], LANDMARKS_PER_HAND), dtype=np.float32)\n",
    "        return np.concatenate([left_pad, arr], axis=1)\n",
    "    else:\n",
    "        # Unknown format: pad/trim to target\n",
    "        return pad_or_sample(arr)\n",
    "\n",
    "\n",
    "print('Helper functions defined (two-hand mode)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf3c998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CELL 6: BUILD DATASET (or Load Cached)\n",
    "# ============================================\n",
    "print('=' * 60)\n",
    "print('BUILDING ARABIC WORD DATASET (TWO-HAND)')\n",
    "print('=' * 60)\n",
    "\n",
    "NPZ_PATH = OUTPUT_DIR / 'arsl_word_sequences_2hand.npz'\n",
    "\n",
    "if NPZ_PATH.exists():\n",
    "    print(f'\\nCached data found: {NPZ_PATH}')\n",
    "    data = np.load(NPZ_PATH)\n",
    "    X, y = data['X'], data['y']\n",
    "    print(f'   X shape : {X.shape}')\n",
    "    print(f'   y shape : {y.shape}')\n",
    "    print(f'   Classes : {len(np.unique(y))}')\n",
    "    print('   Loaded from cache — skipping extraction')\n",
    "else:\n",
    "    if not KARSL_ROOT.exists():\n",
    "        print(f'\\nKArSL dataset NOT FOUND at: {KARSL_ROOT}')\n",
    "        print('Please download KArSL-502 from Kaggle:')\n",
    "        print('https://www.kaggle.com/datasets/yousefelkilany/karsl-502')\n",
    "        print(f'Extract it to: {KARSL_ROOT}')\n",
    "        raise FileNotFoundError(f'KArSL dataset not found: {KARSL_ROOT}')\n",
    "\n",
    "    print(f'\\nLoading KArSL data from: {KARSL_ROOT}')\n",
    "    start_time = time.time()\n",
    "\n",
    "    X_list, y_list = [], []\n",
    "    found_classes, empty_classes = 0, 0\n",
    "\n",
    "    for karsl_class in tqdm(target_karsl_classes, desc='Loading KArSL classes'):\n",
    "        word_id = int(karsl_to_wordid[karsl_class])\n",
    "\n",
    "        # Try common folder naming conventions\n",
    "        candidates = [\n",
    "            KARSL_ROOT / str(karsl_class),\n",
    "            KARSL_ROOT / f'{karsl_class:03d}',\n",
    "            KARSL_ROOT / f'{karsl_class:04d}',\n",
    "            KARSL_ROOT / f'class_{karsl_class}',\n",
    "        ]\n",
    "        class_dir = next((p for p in candidates if p.exists()), None)\n",
    "        if class_dir is None:\n",
    "            empty_classes += 1\n",
    "            continue\n",
    "\n",
    "        found_classes += 1\n",
    "\n",
    "        # Collect all data files\n",
    "        if USE_PREEXTRACTED_KEYPOINTS:\n",
    "            files = list(class_dir.rglob('*.npy')) + list(class_dir.rglob('*.csv'))\n",
    "        else:\n",
    "            files = list(class_dir.rglob('*.mp4'))\n",
    "\n",
    "        if not files:\n",
    "            # Fallback: try all types\n",
    "            files = list(class_dir.rglob('*.npy')) + list(class_dir.rglob('*.csv')) + list(class_dir.rglob('*.mp4'))\n",
    "\n",
    "        for fp in files:\n",
    "            seq = None\n",
    "            try:\n",
    "                if fp.suffix.lower() == '.npy':\n",
    "                    arr = np.load(fp)\n",
    "                    arr_2h = adapt_preextracted_to_2hand(arr)\n",
    "                    seq = pad_or_sample(arr_2h)\n",
    "                elif fp.suffix.lower() == '.csv':\n",
    "                    arr = pd.read_csv(fp).values\n",
    "                    arr_2h = adapt_preextracted_to_2hand(arr)\n",
    "                    seq = pad_or_sample(arr_2h)\n",
    "                elif fp.suffix.lower() == '.mp4':\n",
    "                    seq = extract_from_video_2hand(fp)\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "            if seq is None:\n",
    "                continue\n",
    "\n",
    "            # Skip blank sequences (<20% hand detection)\n",
    "            blank_ratio = np.sum(np.all(seq == 0, axis=1)) / len(seq)\n",
    "            if blank_ratio > 0.8:\n",
    "                continue\n",
    "\n",
    "            X_list.append(seq)\n",
    "            y_list.append(word_id)\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "\n",
    "    X = np.array(X_list, dtype=np.float32)\n",
    "    y = np.array(y_list, dtype=np.int32)\n",
    "\n",
    "    print(f'\\nDataset built in {elapsed:.1f}s ({elapsed/60:.1f} min)')\n",
    "    print(f'   X shape       : {X.shape}')\n",
    "    print(f'   y shape       : {y.shape}')\n",
    "    print(f'   Classes found : {found_classes} / {len(target_karsl_classes)}')\n",
    "    print(f'   Empty classes  : {empty_classes}')\n",
    "\n",
    "    np.savez_compressed(NPZ_PATH, X=X, y=y)\n",
    "    print(f'\\nSaved: {NPZ_PATH}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d3dd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CELL 7: DATA EXPLORATION\n",
    "# ============================================\n",
    "print('=' * 60)\n",
    "print('DATA EXPLORATION')\n",
    "print('=' * 60)\n",
    "\n",
    "# Ensure data is loaded\n",
    "if 'X' not in dir() or 'y' not in dir():\n",
    "    data = np.load(NPZ_PATH)\n",
    "    X, y = data['X'], data['y']\n",
    "\n",
    "unique_ids, counts = np.unique(y, return_counts=True)\n",
    "word_names_en = [id_to_english.get(int(uid), str(uid)) for uid in unique_ids]\n",
    "word_names_ar = [id_to_arabic.get(int(uid), str(uid)) for uid in unique_ids]\n",
    "\n",
    "sort_idx = np.argsort(counts)[::-1]\n",
    "sorted_names  = [word_names_en[i] for i in sort_idx]\n",
    "sorted_counts = counts[sort_idx]\n",
    "\n",
    "# PLOT 1: Class distribution\n",
    "fig, ax = plt.subplots(figsize=(24, 7))\n",
    "ax.bar(range(len(sorted_names)), sorted_counts, color='darkgreen', edgecolor='black', linewidth=0.3)\n",
    "ax.set_xticks(range(len(sorted_names)))\n",
    "ax.set_xticklabels(sorted_names, rotation=90, fontsize=5)\n",
    "ax.set_xlabel('Word', fontsize=12)\n",
    "ax.set_ylabel('Number of Samples', fontsize=12)\n",
    "ax.set_title(f'ArSL Word Dataset (2-Hand) — {len(unique_ids)} classes, {len(y)} total samples', fontsize=14)\n",
    "ax.axhline(y=np.mean(sorted_counts), color='red', linestyle='--', alpha=0.7, label=f'Mean: {np.mean(sorted_counts):.1f}')\n",
    "ax.axhline(y=np.median(sorted_counts), color='orange', linestyle=':', alpha=0.7, label=f'Median: {np.median(sorted_counts):.1f}')\n",
    "ax.legend(fontsize=11)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'\\nDataset Summary:')\n",
    "print(f'   Total samples    : {len(y)}')\n",
    "print(f'   Total classes    : {len(unique_ids)}')\n",
    "print(f'   Features/frame   : {NUM_FEATURES} ({NUM_HANDS} hands)')\n",
    "print(f'   Min samples/class: {counts.min()} ({word_names_en[counts.argmin()]})')\n",
    "print(f'   Max samples/class: {counts.max()} ({word_names_en[counts.argmax()]})')\n",
    "print(f'   Mean             : {counts.mean():.1f}')\n",
    "print(f'   Median           : {np.median(counts):.1f}')\n",
    "\n",
    "# PLOT 2: Quality analysis\n",
    "fig, axes = plt.subplots(1, 3, figsize=(22, 5))\n",
    "\n",
    "axes[0].hist(sorted_counts, bins=20, color='darkgreen', edgecolor='black', alpha=0.85)\n",
    "axes[0].set_xlabel('Samples per Class', fontsize=11)\n",
    "axes[0].set_ylabel('Number of Classes', fontsize=11)\n",
    "axes[0].set_title('Samples per Class Distribution', fontsize=13)\n",
    "axes[0].axvline(x=np.mean(sorted_counts), color='red', linestyle='--', label=f'Mean: {np.mean(sorted_counts):.1f}')\n",
    "axes[0].legend(fontsize=9)\n",
    "\n",
    "# Zero-frame quality for left hand\n",
    "left_zero = []\n",
    "right_zero = []\n",
    "for i in range(min(len(X), 1000)):\n",
    "    left_sums = np.sum(np.abs(X[i, :, :LANDMARKS_PER_HAND]), axis=1)\n",
    "    right_sums = np.sum(np.abs(X[i, :, LANDMARKS_PER_HAND:]), axis=1)\n",
    "    left_zero.append(np.sum(left_sums == 0) / SEQUENCE_LENGTH * 100)\n",
    "    right_zero.append(np.sum(right_sums == 0) / SEQUENCE_LENGTH * 100)\n",
    "\n",
    "axes[1].hist(left_zero, bins=20, alpha=0.7, color='#2196F3', edgecolor='navy', label='Left hand')\n",
    "axes[1].hist(right_zero, bins=20, alpha=0.7, color='#FF9800', edgecolor='darkred', label='Right hand')\n",
    "axes[1].set_xlabel('% Zero Frames', fontsize=11)\n",
    "axes[1].set_ylabel('Number of Samples', fontsize=11)\n",
    "axes[1].set_title('Per-Hand Zero Frame Analysis', fontsize=13)\n",
    "axes[1].legend(fontsize=9)\n",
    "\n",
    "# Two-hand detection rate\n",
    "both_hands = []\n",
    "for i in range(min(len(X), 1000)):\n",
    "    left_active = np.any(X[i, :, :LANDMARKS_PER_HAND] != 0, axis=1)\n",
    "    right_active = np.any(X[i, :, LANDMARKS_PER_HAND:] != 0, axis=1)\n",
    "    both_active = np.sum(left_active & right_active) / SEQUENCE_LENGTH * 100\n",
    "    both_hands.append(both_active)\n",
    "\n",
    "axes[2].hist(both_hands, bins=20, color='#4CAF50', edgecolor='darkgreen', alpha=0.85)\n",
    "axes[2].set_xlabel('% Frames with Both Hands', fontsize=11)\n",
    "axes[2].set_ylabel('Number of Samples', fontsize=11)\n",
    "axes[2].set_title(f'Two-Hand Detection Rate (mean: {np.mean(both_hands):.1f}%)', fontsize=13)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'\\nTwo-Hand Stats (first {min(len(X), 1000)} samples):')\n",
    "print(f'   Mean both-hands frames: {np.mean(both_hands):.1f}%')\n",
    "print(f'   Samples with >50% both: {np.sum(np.array(both_hands) > 50)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3663b766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CELL 8: PREPROCESSING & DATA SPLITS\n",
    "# ============================================\n",
    "print('=' * 60)\n",
    "print('PREPROCESSING & TRAIN/VAL/TEST SPLIT')\n",
    "print('=' * 60)\n",
    "\n",
    "# Reload from cache\n",
    "data = np.load(NPZ_PATH)\n",
    "X, y = data['X'], data['y']\n",
    "\n",
    "# StandardScaler normalization (per-feature)\n",
    "original_shape = X.shape\n",
    "X_flat = X.reshape(-1, NUM_FEATURES)\n",
    "scaler = StandardScaler()\n",
    "X_flat = scaler.fit_transform(X_flat)\n",
    "X = X_flat.reshape(original_shape).astype(np.float32)\n",
    "print(f'   StandardScaler applied: mean~0, std~1 per feature')\n",
    "\n",
    "# Encode labels\n",
    "encoder = LabelEncoder()\n",
    "y_encoded = encoder.fit_transform(y)\n",
    "num_classes = len(encoder.classes_)\n",
    "y_onehot = to_categorical(y_encoded, num_classes=num_classes)\n",
    "\n",
    "# Stratified split: 60/20/20\n",
    "try:\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "        X, y_onehot, test_size=TEST_SIZE, random_state=42, stratify=y_encoded\n",
    "    )\n",
    "    temp_labels = np.argmax(y_temp, axis=1)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(\n",
    "        X_temp, y_temp, test_size=0.5, random_state=42, stratify=temp_labels\n",
    "    )\n",
    "except ValueError:\n",
    "    print('Some classes have too few samples for stratification. Using random split.')\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "        X, y_onehot, test_size=TEST_SIZE, random_state=42\n",
    "    )\n",
    "    X_val, X_test, y_val, y_test = train_test_split(\n",
    "        X_temp, y_temp, test_size=0.5, random_state=42\n",
    "    )\n",
    "\n",
    "# Class weights for imbalanced data\n",
    "train_labels = np.argmax(y_train, axis=1)\n",
    "cw = compute_class_weight('balanced', classes=np.arange(num_classes), y=train_labels)\n",
    "cw = np.clip(cw, 0.5, 10.0)  # clip extreme weights\n",
    "class_weights = dict(enumerate(cw))\n",
    "\n",
    "print(f'\\nSplit Summary:')\n",
    "print(f'   Classes      : {num_classes}')\n",
    "print(f'   Train        : {X_train.shape[0]} ({X_train.shape[0]/len(X)*100:.0f}%)')\n",
    "print(f'   Validation   : {X_val.shape[0]} ({X_val.shape[0]/len(X)*100:.0f}%)')\n",
    "print(f'   Test         : {X_test.shape[0]} ({X_test.shape[0]/len(X)*100:.0f}%)')\n",
    "print(f'   Input shape  : {X_train.shape[1:]}')\n",
    "print(f'   Class weights: balanced (clipped [0.5, 10]) — max: {max(cw):.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac951f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CELL 9: BUILD & TRAIN BiLSTM (FULL PARAMETERS)\n",
    "# ============================================\n",
    "print('=' * 60)\n",
    "print('BUILDING & TRAINING OPTIMIZED BiLSTM MODEL')\n",
    "print('   Two-Hand Mode | Full Parameters | GPU-Accelerated')\n",
    "print('=' * 60)\n",
    "\n",
    "# Clear previous session\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "BATCH_SIZE_TRAIN = BATCH_SIZE if USE_GPU else 32\n",
    "print(f'   Batch size: {BATCH_SIZE_TRAIN} ({\"GPU\" if USE_GPU else \"CPU\"})')\n",
    "\n",
    "# --- Data Augmentation ---\n",
    "def augment_sequence(x, y):\n",
    "    \"\"\"Apply augmentations to two-hand landmark sequences.\"\"\"\n",
    "    # 1) Gaussian noise\n",
    "    noise = tf.random.normal(shape=tf.shape(x), mean=0.0, stddev=0.005)\n",
    "    x = x + noise\n",
    "\n",
    "    # 2) Random temporal shift: roll frames by +/-3\n",
    "    shift = tf.random.uniform([], minval=-3, maxval=4, dtype=tf.int32)\n",
    "    x = tf.roll(x, shift=shift, axis=0)\n",
    "\n",
    "    # 3) Random frame dropout: zero out ~10% of frames\n",
    "    frame_mask = tf.random.uniform([SEQUENCE_LENGTH, 1]) > 0.1\n",
    "    frame_mask = tf.cast(frame_mask, tf.float32)\n",
    "    x = x * frame_mask\n",
    "\n",
    "    # 4) Random scaling (simulate distance variation)\n",
    "    scale = tf.random.uniform([], 0.85, 1.15)\n",
    "    x = x * scale\n",
    "\n",
    "    # 5) Random hand swap (data augmentation for symmetry)\n",
    "    # Swap left/right hand landmarks with 20% probability\n",
    "    swap = tf.random.uniform([]) < 0.2\n",
    "    if swap:\n",
    "        left = x[:, :LANDMARKS_PER_HAND]\n",
    "        right = x[:, LANDMARKS_PER_HAND:]\n",
    "        x = tf.concat([right, left], axis=1)\n",
    "\n",
    "    return x, y\n",
    "\n",
    "# --- tf.data Pipelines ---\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "train_ds = train_ds.shuffle(buffer_size=min(len(X_train), 10000), seed=42, reshuffle_each_iteration=True)\n",
    "train_ds = train_ds.map(augment_sequence, num_parallel_calls=AUTOTUNE)\n",
    "train_ds = train_ds.batch(BATCH_SIZE_TRAIN).prefetch(AUTOTUNE)\n",
    "\n",
    "val_ds = tf.data.Dataset.from_tensor_slices((X_val, y_val))\n",
    "val_ds = val_ds.batch(BATCH_SIZE_TRAIN).prefetch(AUTOTUNE)\n",
    "\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "test_ds = test_ds.batch(BATCH_SIZE_TRAIN).prefetch(AUTOTUNE)\n",
    "\n",
    "print(f'   tf.data pipelines with augmentation ready')\n",
    "print(f'   Class weights for {len(class_weights)} classes')\n",
    "\n",
    "# --- Temporal Attention Layer ---\n",
    "class TemporalAttention(tf.keras.layers.Layer):\n",
    "    \"\"\"Learnable attention over time steps.\"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.W = self.add_weight(name='att_weight', shape=(input_shape[-1], 1),\n",
    "                                 initializer='glorot_uniform', trainable=True)\n",
    "        self.b = self.add_weight(name='att_bias', shape=(input_shape[1], 1),\n",
    "                                 initializer='zeros', trainable=True)\n",
    "\n",
    "    def call(self, x):\n",
    "        e = tf.nn.tanh(tf.matmul(x, self.W) + self.b)\n",
    "        a = tf.nn.softmax(e, axis=1)\n",
    "        output = tf.reduce_sum(x * a, axis=1)\n",
    "        return output\n",
    "\n",
    "# --- Build Model (Full Parameters) ---\n",
    "with tf.device(DEVICE):\n",
    "    model = Sequential([\n",
    "        Input(shape=(SEQUENCE_LENGTH, NUM_FEATURES), name='landmark_sequence'),\n",
    "\n",
    "        # BiLSTM block 1 — captures broad temporal patterns from both hands\n",
    "        Bidirectional(LSTM(LSTM_UNITS_1, return_sequences=True,\n",
    "                           recurrent_dropout=0.0,\n",
    "                           kernel_regularizer=tf.keras.regularizers.l2(L2_REG)),\n",
    "                      name='bilstm_1'),\n",
    "        BatchNormalization(name='bn_1'),\n",
    "        tf.keras.layers.SpatialDropout1D(DROPOUT_RATE, name='sdrop_1'),\n",
    "\n",
    "        # BiLSTM block 2 — refines temporal features\n",
    "        Bidirectional(LSTM(LSTM_UNITS_2, return_sequences=True,\n",
    "                           kernel_regularizer=tf.keras.regularizers.l2(L2_REG)),\n",
    "                      name='bilstm_2'),\n",
    "        BatchNormalization(name='bn_2'),\n",
    "        tf.keras.layers.SpatialDropout1D(DROPOUT_RATE, name='sdrop_2'),\n",
    "\n",
    "        # LSTM block 3 — final temporal encoding\n",
    "        LSTM(LSTM_UNITS_3, return_sequences=True,\n",
    "             kernel_regularizer=tf.keras.regularizers.l2(L2_REG),\n",
    "             name='lstm_3'),\n",
    "        BatchNormalization(name='bn_3'),\n",
    "\n",
    "        # Temporal Attention — focus on discriminative frames\n",
    "        TemporalAttention(name='temporal_attention'),\n",
    "        Dropout(DROPOUT_RATE, name='drop_att'),\n",
    "\n",
    "        # Dense classifier head\n",
    "        Dense(DENSE_UNITS, activation='relu',\n",
    "              kernel_initializer='he_normal',\n",
    "              kernel_regularizer=tf.keras.regularizers.l2(L2_REG),\n",
    "              name='dense_1'),\n",
    "        BatchNormalization(name='bn_dense'),\n",
    "        Dropout(DROPOUT_RATE, name='drop_dense'),\n",
    "\n",
    "        Dense(DENSE_UNITS // 2, activation='relu',\n",
    "              kernel_initializer='he_normal',\n",
    "              kernel_regularizer=tf.keras.regularizers.l2(L2_REG),\n",
    "              name='dense_2'),\n",
    "        BatchNormalization(name='bn_dense_2'),\n",
    "        Dropout(DROPOUT_RATE * 0.5, name='drop_dense_2'),\n",
    "\n",
    "        Dense(num_classes, activation='softmax', dtype='float32', name='output')\n",
    "    ], name='ArSL_Word_BiLSTM_2Hand')\n",
    "\n",
    "# Optimizer with gradient clipping\n",
    "optimizer = tf.keras.optimizers.legacy.Adam(\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    clipnorm=GRAD_CLIP_NORM\n",
    ")\n",
    "\n",
    "# Loss with label smoothing\n",
    "loss_fn = tf.keras.losses.CategoricalCrossentropy(label_smoothing=LABEL_SMOOTH)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=loss_fn,\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print('\\nModel Architecture:')\n",
    "model.summary()\n",
    "print(f'\\nTraining on: {DEVICE}')\n",
    "print(f'Input: {NUM_HANDS} hands x {LANDMARKS_PER_HAND} features = {NUM_FEATURES} total')\n",
    "\n",
    "# --- Callbacks ---\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\n",
    "        str(OUTPUT_DIR / 'arsl_word_lstm_model_best.h5'),\n",
    "        monitor='val_accuracy', save_best_only=True, mode='max', verbose=1\n",
    "    ),\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss', patience=25, restore_best_weights=True, verbose=1\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss', factor=0.5, patience=8, min_lr=1e-7, verbose=1\n",
    "    ),\n",
    "    tf.keras.callbacks.TerminateOnNaN()\n",
    "]\n",
    "\n",
    "# --- Train ---\n",
    "print('\\nStarting training...')\n",
    "print(f'   Device       : {DEVICE}')\n",
    "print(f'   Batch size   : {BATCH_SIZE_TRAIN}')\n",
    "print(f'   Max epochs   : {EPOCHS}')\n",
    "print(f'   LR           : {LEARNING_RATE}')\n",
    "print(f'   Label smooth : {LABEL_SMOOTH}')\n",
    "print(f'   Grad clip    : {GRAD_CLIP_NORM}')\n",
    "print(f'   Augmentation : ON (noise + shift + dropout + scale + hand swap)')\n",
    "start_time = time.time()\n",
    "\n",
    "with tf.device(DEVICE):\n",
    "    history = model.fit(\n",
    "        train_ds,\n",
    "        validation_data=val_ds,\n",
    "        epochs=EPOCHS,\n",
    "        callbacks=callbacks,\n",
    "        class_weight=class_weights,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(f'\\nTraining complete in {training_time:.1f}s ({training_time/60:.1f} min)')\n",
    "\n",
    "# Save final model + class mapping\n",
    "model.save(str(OUTPUT_DIR / 'arsl_word_lstm_model_final.h5'))\n",
    "class_df = pd.DataFrame({\n",
    "    'model_class_index': range(num_classes),\n",
    "    'word_id': encoder.classes_.tolist()\n",
    "})\n",
    "class_df.to_csv(OUTPUT_DIR / 'arsl_word_classes.csv', index=False)\n",
    "print(f'\\nFinal model : {OUTPUT_DIR / \"arsl_word_lstm_model_final.h5\"}')\n",
    "print(f'Best model  : {OUTPUT_DIR / \"arsl_word_lstm_model_best.h5\"}')\n",
    "print(f'Classes CSV : {OUTPUT_DIR / \"arsl_word_classes.csv\"}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3a7292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CELL 10: EVALUATION & VISUALIZATION DASHBOARD\n",
    "# ============================================\n",
    "print('=' * 60)\n",
    "print('MODEL EVALUATION & VISUALIZATION DASHBOARD')\n",
    "print('=' * 60)\n",
    "\n",
    "# Load best checkpoint\n",
    "best_model = tf.keras.models.load_model(\n",
    "    str(OUTPUT_DIR / 'arsl_word_lstm_model_best.h5'),\n",
    "    custom_objects={'TemporalAttention': TemporalAttention}\n",
    ")\n",
    "\n",
    "# Predict\n",
    "eval_batch = 64 if USE_GPU else 32\n",
    "eval_ds = tf.data.Dataset.from_tensor_slices((X_test,)).batch(eval_batch).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "with tf.device(DEVICE):\n",
    "    proba = best_model.predict(eval_ds, verbose=0)\n",
    "\n",
    "y_pred = np.argmax(proba, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Top-1 accuracy\n",
    "top1_acc = (y_pred == y_true).mean()\n",
    "\n",
    "# Top-5 accuracy\n",
    "top5_correct = 0\n",
    "for i in range(len(y_true)):\n",
    "    top5 = np.argsort(proba[i])[-5:]\n",
    "    if y_true[i] in top5:\n",
    "        top5_correct += 1\n",
    "top5_acc = top5_correct / len(y_true)\n",
    "\n",
    "print(f'\\nTest Results (Two-Hand Model):')\n",
    "print(f'   Top-1 Accuracy : {top1_acc:.4f} ({top1_acc*100:.2f}%)')\n",
    "print(f'   Top-5 Accuracy : {top5_acc:.4f} ({top5_acc*100:.2f}%)')\n",
    "print(f'   Test samples   : {len(y_true)}')\n",
    "print(f'   Classes        : {num_classes}')\n",
    "print(f'   Features       : {NUM_FEATURES} ({NUM_HANDS} hands)')\n",
    "\n",
    "# =============================================\n",
    "# PLOT 1: Training Dashboard (4 panels)\n",
    "# =============================================\n",
    "fig, axes = plt.subplots(2, 2, figsize=(18, 12))\n",
    "\n",
    "axes[0, 0].plot(history.history['accuracy'], label='Train', linewidth=2, color='#2E7D32')\n",
    "axes[0, 0].plot(history.history['val_accuracy'], label='Validation', linewidth=2, color='#FF9800')\n",
    "axes[0, 0].fill_between(range(len(history.history['accuracy'])),\n",
    "                         history.history['accuracy'], history.history['val_accuracy'],\n",
    "                         alpha=0.1, color='red')\n",
    "axes[0, 0].set_title('Accuracy over Epochs', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Accuracy')\n",
    "axes[0, 0].legend(fontsize=11)\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "axes[0, 0].set_ylim([0, 1.05])\n",
    "best_epoch = np.argmax(history.history['val_accuracy'])\n",
    "axes[0, 0].axvline(x=best_epoch, color='blue', linestyle=':', alpha=0.5)\n",
    "\n",
    "axes[0, 1].plot(history.history['loss'], label='Train', linewidth=2, color='#2E7D32')\n",
    "axes[0, 1].plot(history.history['val_loss'], label='Validation', linewidth=2, color='#FF9800')\n",
    "axes[0, 1].fill_between(range(len(history.history['loss'])),\n",
    "                         history.history['loss'], history.history['val_loss'],\n",
    "                         alpha=0.1, color='red')\n",
    "axes[0, 1].set_title('Loss over Epochs', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('Loss')\n",
    "axes[0, 1].legend(fontsize=11)\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "if 'lr' in history.history:\n",
    "    lr_values = history.history['lr']\n",
    "else:\n",
    "    lr_values = [LEARNING_RATE] * len(history.history['loss'])\n",
    "axes[1, 0].plot(lr_values, linewidth=2, color='#4CAF50', marker='o', markersize=3)\n",
    "axes[1, 0].set_title('Learning Rate Schedule', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('Learning Rate')\n",
    "axes[1, 0].set_yscale('log')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "train_acc = np.array(history.history['accuracy'])\n",
    "val_acc = np.array(history.history['val_accuracy'])\n",
    "gap = train_acc - val_acc\n",
    "axes[1, 1].bar(range(len(gap)), gap, color=['green' if g < 0.05 else 'orange' if g < 0.15 else 'red' for g in gap],\n",
    "               edgecolor='black', linewidth=0.3, alpha=0.8)\n",
    "axes[1, 1].axhline(y=0.05, color='green', linestyle='--', alpha=0.5, label='Healthy gap (5%)')\n",
    "axes[1, 1].axhline(y=0.15, color='red', linestyle='--', alpha=0.5, label='Overfitting (15%)')\n",
    "axes[1, 1].set_title('Overfitting Monitor', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Epoch')\n",
    "axes[1, 1].set_ylabel('Accuracy Gap')\n",
    "axes[1, 1].legend(fontsize=9)\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle(f'ArSL Word BiLSTM (2-Hand) — Top-1: {top1_acc*100:.1f}%, Top-5: {top5_acc*100:.1f}%',\n",
    "             fontsize=16, fontweight='bold', y=1.01)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# =============================================\n",
    "# PLOT 2: Confidence Distribution\n",
    "# =============================================\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "correct_mask = y_pred == y_true\n",
    "correct_conf = np.max(proba[correct_mask], axis=1)\n",
    "wrong_conf   = np.max(proba[~correct_mask], axis=1) if np.sum(~correct_mask) > 0 else np.array([])\n",
    "\n",
    "axes[0].hist(correct_conf, bins=30, alpha=0.7, color='#4CAF50', edgecolor='darkgreen', label=f'Correct ({len(correct_conf)})')\n",
    "if len(wrong_conf) > 0:\n",
    "    axes[0].hist(wrong_conf, bins=30, alpha=0.7, color='#F44336', edgecolor='darkred', label=f'Wrong ({len(wrong_conf)})')\n",
    "axes[0].set_xlabel('Prediction Confidence', fontsize=12)\n",
    "axes[0].set_ylabel('Count', fontsize=12)\n",
    "axes[0].set_title('Confidence: Correct vs Wrong', fontsize=13)\n",
    "axes[0].legend(fontsize=11)\n",
    "\n",
    "top1_conf = np.max(proba, axis=1)\n",
    "sorted_proba = np.sort(proba, axis=1)[:, ::-1]\n",
    "top2_conf = sorted_proba[:, 1] if proba.shape[1] > 1 else np.zeros(len(proba))\n",
    "margin = top1_conf - top2_conf\n",
    "\n",
    "axes[1].hist(margin, bins=30, color='#9C27B0', edgecolor='purple', alpha=0.8)\n",
    "axes[1].set_xlabel('Confidence Margin (Top-1 - Top-2)', fontsize=12)\n",
    "axes[1].set_ylabel('Count', fontsize=12)\n",
    "axes[1].set_title(f'Decision Margin — Mean: {np.mean(margin):.3f}', fontsize=13)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# =============================================\n",
    "# Classification Report\n",
    "# =============================================\n",
    "word_labels = []\n",
    "for cls_idx in range(num_classes):\n",
    "    wid = int(encoder.classes_[cls_idx])\n",
    "    word_labels.append(id_to_english.get(wid, str(wid)))\n",
    "\n",
    "print('\\nClassification Report:')\n",
    "report = classification_report(y_true, y_pred, labels=range(num_classes), target_names=word_labels, zero_division=0, output_dict=True)\n",
    "print(classification_report(y_true, y_pred, labels=range(num_classes), target_names=word_labels, zero_division=0))\n",
    "\n",
    "# =============================================\n",
    "# PLOT 3: Per-Class F1 Score\n",
    "# =============================================\n",
    "class_f1 = {k: v['f1-score'] for k, v in report.items() if k in word_labels}\n",
    "sorted_f1 = sorted(class_f1.items(), key=lambda x: x[1], reverse=True)\n",
    "f1_names = [x[0] for x in sorted_f1]\n",
    "f1_vals  = [x[1] for x in sorted_f1]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(24, 6))\n",
    "colors_f1 = ['#4CAF50' if v >= 0.7 else '#FF9800' if v >= 0.4 else '#F44336' for v in f1_vals]\n",
    "ax.bar(range(len(f1_names)), f1_vals, color=colors_f1, edgecolor='black', linewidth=0.3)\n",
    "ax.set_xticks(range(len(f1_names)))\n",
    "ax.set_xticklabels(f1_names, rotation=90, fontsize=6)\n",
    "ax.set_xlabel('Word', fontsize=12)\n",
    "ax.set_ylabel('F1 Score', fontsize=12)\n",
    "ax.set_title(f'Per-Class F1 (green>=0.7, orange>=0.4, red<0.4) — Mean: {np.mean(f1_vals):.3f}', fontsize=14)\n",
    "ax.axhline(y=np.mean(f1_vals), color='blue', linestyle='--', alpha=0.5, label=f'Mean F1: {np.mean(f1_vals):.3f}')\n",
    "ax.legend(fontsize=11)\n",
    "ax.set_ylim([0, 1.05])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# =============================================\n",
    "# PLOT 4: Confusion Matrix\n",
    "# =============================================\n",
    "cm = confusion_matrix(y_true, y_pred, labels=range(num_classes))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 18))\n",
    "if num_classes <= 50:\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Greens',\n",
    "                xticklabels=word_labels, yticklabels=word_labels, ax=ax,\n",
    "                linewidths=0.5, linecolor='lightgray')\n",
    "else:\n",
    "    sns.heatmap(cm, annot=False, cmap='Greens',\n",
    "                xticklabels=word_labels, yticklabels=word_labels, ax=ax)\n",
    "ax.set_title(f'ArSL Confusion Matrix — {num_classes} classes (Top-1: {top1_acc*100:.1f}%)', fontsize=15)\n",
    "ax.set_xlabel('Predicted', fontsize=13)\n",
    "ax.set_ylabel('True', fontsize=13)\n",
    "plt.xticks(rotation=90, fontsize=5)\n",
    "plt.yticks(fontsize=5)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# =============================================\n",
    "# PLOT 5: Top-10 Most Confused Pairs\n",
    "# =============================================\n",
    "np.fill_diagonal(cm, 0)\n",
    "confused_pairs = []\n",
    "for i in range(num_classes):\n",
    "    for j in range(num_classes):\n",
    "        if cm[i, j] > 0:\n",
    "            confused_pairs.append((word_labels[i], word_labels[j], cm[i, j]))\n",
    "confused_pairs.sort(key=lambda x: x[2], reverse=True)\n",
    "top_confused = confused_pairs[:10]\n",
    "\n",
    "if top_confused:\n",
    "    fig, ax = plt.subplots(figsize=(14, 6))\n",
    "    pair_labels = [f'{p[0]} -> {p[1]}' for p in top_confused]\n",
    "    pair_counts = [p[2] for p in top_confused]\n",
    "    bars = ax.barh(range(len(pair_labels)), pair_counts, color='#E91E63', edgecolor='darkred', alpha=0.85)\n",
    "    ax.set_yticks(range(len(pair_labels)))\n",
    "    ax.set_yticklabels(pair_labels, fontsize=10)\n",
    "    ax.set_xlabel('Misclassification Count', fontsize=12)\n",
    "    ax.set_title('Top-10 Most Confused Pairs', fontsize=14, fontweight='bold')\n",
    "    ax.invert_yaxis()\n",
    "    for bar, count in zip(bars, pair_counts):\n",
    "        ax.text(bar.get_width() + 0.3, bar.get_y() + bar.get_height()/2,\n",
    "                str(count), va='center', fontsize=10, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# =============================================\n",
    "# PLOT 6: Per-Category Accuracy\n",
    "# =============================================\n",
    "cat_map = dict(zip(vocab_df['word_id'].astype(int), vocab_df['category']))\n",
    "category_correct, category_total = {}, {}\n",
    "for i in range(len(y_true)):\n",
    "    wid = int(encoder.classes_[y_true[i]])\n",
    "    cat = cat_map.get(wid, 'unknown')\n",
    "    category_total[cat] = category_total.get(cat, 0) + 1\n",
    "    if y_pred[i] == y_true[i]:\n",
    "        category_correct[cat] = category_correct.get(cat, 0) + 1\n",
    "\n",
    "cat_names = sorted(category_total.keys())\n",
    "cat_accs  = [category_correct.get(c, 0) / category_total[c] for c in cat_names]\n",
    "cat_sizes = [category_total[c] for c in cat_names]\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(14, 6))\n",
    "x_pos = range(len(cat_names))\n",
    "bars = ax1.bar(x_pos, [a * 100 for a in cat_accs], color='#2E7D32', edgecolor='black', alpha=0.85)\n",
    "ax1.set_xticks(x_pos)\n",
    "ax1.set_xticklabels(cat_names, rotation=45, ha='right', fontsize=11)\n",
    "ax1.set_ylabel('Accuracy (%)', fontsize=12)\n",
    "ax1.set_ylim([0, 105])\n",
    "\n",
    "for bar, acc, size in zip(bars, cat_accs, cat_sizes):\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,\n",
    "             f'{acc*100:.1f}%\\n(n={size})', ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
    "\n",
    "ax1.set_title('Per-Category Accuracy', fontsize=14, fontweight='bold')\n",
    "ax1.axhline(y=top1_acc*100, color='red', linestyle='--', alpha=0.5, label=f'Overall: {top1_acc*100:.1f}%')\n",
    "ax1.legend(fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# =============================================\n",
    "# PLOT 7: Best & Worst Performing Classes\n",
    "# =============================================\n",
    "per_class_acc = {}\n",
    "for i in range(num_classes):\n",
    "    mask = y_true == i\n",
    "    if mask.sum() > 0:\n",
    "        per_class_acc[word_labels[i]] = (y_pred[mask] == i).mean()\n",
    "\n",
    "sorted_acc = sorted(per_class_acc.items(), key=lambda x: x[1])\n",
    "n_show = min(10, len(sorted_acc))\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 6))\n",
    "\n",
    "worst = sorted_acc[:n_show]\n",
    "ax1.barh(range(len(worst)), [w[1]*100 for w in worst], color='#F44336', edgecolor='darkred', alpha=0.85)\n",
    "ax1.set_yticks(range(len(worst)))\n",
    "ax1.set_yticklabels([w[0] for w in worst], fontsize=10)\n",
    "ax1.set_xlabel('Accuracy (%)', fontsize=12)\n",
    "ax1.set_title(f'Bottom {n_show} Classes', fontsize=14, fontweight='bold', color='#F44336')\n",
    "ax1.set_xlim([0, 105])\n",
    "for i, w in enumerate(worst):\n",
    "    ax1.text(w[1]*100 + 1, i, f'{w[1]*100:.1f}%', va='center', fontsize=10)\n",
    "\n",
    "best = sorted_acc[-n_show:][::-1]\n",
    "ax2.barh(range(len(best)), [b[1]*100 for b in best], color='#4CAF50', edgecolor='darkgreen', alpha=0.85)\n",
    "ax2.set_yticks(range(len(best)))\n",
    "ax2.set_yticklabels([b[0] for b in best], fontsize=10)\n",
    "ax2.set_xlabel('Accuracy (%)', fontsize=12)\n",
    "ax2.set_title(f'Top {n_show} Classes', fontsize=14, fontweight='bold', color='#4CAF50')\n",
    "ax2.set_xlim([0, 105])\n",
    "for i, b in enumerate(best):\n",
    "    ax2.text(b[1]*100 + 1, i, f'{b[1]*100:.1f}%', va='center', fontsize=10)\n",
    "\n",
    "plt.suptitle('Best vs Worst Performing Classes (Two-Hand Model)', fontsize=15, fontweight='bold', y=1.01)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# =============================================\n",
    "# PLOT 8: Precision vs Recall Scatter\n",
    "# =============================================\n",
    "precisions = [report[w]['precision'] for w in word_labels if w in report]\n",
    "recalls = [report[w]['recall'] for w in word_labels if w in report]\n",
    "f1s = [report[w]['f1-score'] for w in word_labels if w in report]\n",
    "labels_in_report = [w for w in word_labels if w in report]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "scatter = ax.scatter(recalls, precisions, c=f1s, cmap='RdYlGn', s=50, edgecolors='black', linewidth=0.5, alpha=0.8)\n",
    "plt.colorbar(scatter, label='F1 Score', ax=ax)\n",
    "ax.set_xlabel('Recall', fontsize=13)\n",
    "ax.set_ylabel('Precision', fontsize=13)\n",
    "ax.set_title('Precision vs Recall per Class (color = F1)', fontsize=14, fontweight='bold')\n",
    "ax.set_xlim([-0.05, 1.05])\n",
    "ax.set_ylim([-0.05, 1.05])\n",
    "ax.plot([0, 1], [0, 1], 'k--', alpha=0.2)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "for i, lbl in enumerate(labels_in_report):\n",
    "    if f1s[i] < 0.3:\n",
    "        ax.annotate(lbl, (recalls[i], precisions[i]), fontsize=7, alpha=0.8,\n",
    "                    xytext=(5, 5), textcoords='offset points')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('\\n' + '=' * 60)\n",
    "print('Evaluation Dashboard complete!')\n",
    "print('=' * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8759e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CELL 11: DOWNLOAD MODELS (Kaggle)\n",
    "# ============================================\n",
    "# Download the trained model files from Kaggle output\n",
    "\n",
    "if IS_KAGGLE:\n",
    "    print('Model files available for download in /kaggle/working/:')\n",
    "    for f in OUTPUT_DIR.glob('*'):\n",
    "        size_mb = f.stat().st_size / (1024 * 1024)\n",
    "        print(f'   {f.name} ({size_mb:.1f} MB)')\n",
    "    print('\\nDownload these files and place them in your local ArSL Word (Arabic) folder')\n",
    "else:\n",
    "    print('Model files saved to:')\n",
    "    print(f'   {OUTPUT_DIR}')\n",
    "    for f in OUTPUT_DIR.glob('arsl_word_*'):\n",
    "        size_mb = f.stat().st_size / (1024 * 1024)\n",
    "        print(f'   {f.name} ({size_mb:.1f} MB)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dffab11",
   "metadata": {},
   "source": [
    "## Kaggle Tips & Troubleshooting\n",
    "\n",
    "| Issue                   | Solution                                                     |\n",
    "| ----------------------- | ------------------------------------------------------------ |\n",
    "| **OOM (Out of Memory)** | Reduce `BATCH_SIZE` to 32 or 16                              |\n",
    "| **No GPU detected**     | Enable GPU in notebook settings (Accelerator dropdown)       |\n",
    "| **Slow extraction**     | Pre-extract sequences locally, upload `.npz` to Kaggle       |\n",
    "| **Low accuracy**        | Increase `EPOCHS`, add more data, tune `LSTM_UNITS`          |\n",
    "| **NaN loss**            | Set `ENABLE_MIXED_PRECISION = False`, reduce `LEARNING_RATE` |\n",
    "| **Dataset not found**   | Check Kaggle dataset names match paths in Cell 3             |\n",
    "\n",
    "### Two-Hand Model vs One-Hand:\n",
    "\n",
    "- **One-hand (63 features)**: Faster extraction, works for single-hand signs\n",
    "- **Two-hand (126 features)**: Captures signs requiring both hands\n",
    "- Pre-extracted 1-hand keypoints are automatically padded to 2-hand format (right-hand slot)\n",
    "\n",
    "### KArSL Dataset:\n",
    "\n",
    "- Download from [Kaggle: KArSL-502](https://www.kaggle.com/datasets/yousefelkilany/karsl-502)\n",
    "- Supports pre-extracted keypoints (.npy/.csv) or raw video (.mp4)\n",
    "- Set `USE_PREEXTRACTED_KEYPOINTS = True/False` in Cell 3\n",
    "\n",
    "### Architecture Match:\n",
    "\n",
    "- This model uses the **same BiLSTM + TemporalAttention** architecture as the English ASL Word model\n",
    "- Both share `shared_word_vocabulary.csv` for bilingual word mapping\n",
    "- Output class mapping: `arsl_word_classes.csv` maps model indices to `word_id`\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
