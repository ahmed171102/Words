# Letters + Words Integration â€” Combined System Design

> **How letters and words will work together in real-time**

---

## The Big Picture: "My name is Ahmed"

Here's exactly how a user would sign this sentence using **both** the letter and word models together:

```
User signs:              System recognizes:         Output built:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
[word sign: "my"]     â†’  Word Model â†’ word_id=X   â†’ "my"
[word sign: "name"]   â†’  Word Model â†’ word_id=X   â†’ "my name"
                         (pause â€” switch to letters)
[letter: A]           â†’  Letter Model â†’ "A"       â†’ "my name A"
[letter: H]           â†’  Letter Model â†’ "H"       â†’ "my name AH"
[letter: M]           â†’  Letter Model â†’ "M"       â†’ "my name AHM"
[letter: E]           â†’  Letter Model â†’ "E"       â†’ "my name AHME"
[letter: D]           â†’  Letter Model â†’ "D"       â†’ "my name AHMED"
                         (pause â€” back to words)
[word sign: "help"]   â†’  Word Model â†’ word_id=2   â†’ "my name AHMED help"
```

**Yes, this absolutely works** â€” and it's how real sign language interpreters work too.  
Signers naturally switch between **word signs** (common words) and **fingerspelling** (names, technical terms).

---

## Architecture: Dual-Model Real-Time System

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚         WEBCAM FEED            â”‚
                    â”‚    (30 FPS continuous)          â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚      MediaPipe Hand Detection   â”‚
                    â”‚   21 landmarks Ã— 3 = 63 featuresâ”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚       MODE DETECTOR             â”‚
                    â”‚  "Is the hand moving or still?"  â”‚
                    â”‚                                  â”‚
                    â”‚  Still hand â†’ LETTER MODE        â”‚
                    â”‚  Moving hand â†’ WORD MODE         â”‚
                    â”‚  No hand â†’ IDLE (space/pause)    â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚          â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”  â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚  LETTER MODEL   â”‚  â”‚    WORD MODEL          â”‚
              â”‚  (MLP)          â”‚  â”‚    (BiLSTM)            â”‚
              â”‚                 â”‚  â”‚                        â”‚
              â”‚  Input: (1, 63) â”‚  â”‚  Input: (30, 63)       â”‚
              â”‚  1 frame        â”‚  â”‚  30-frame window       â”‚
              â”‚  â†’ predicted    â”‚  â”‚  â†’ predicted word_id   â”‚
              â”‚    letter       â”‚  â”‚                        â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚                    â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚           SENTENCE BUILDER                   â”‚
              â”‚                                              â”‚
              â”‚  Letter decoder: stability + cooldown        â”‚
              â”‚  Word decoder: confidence threshold          â”‚
              â”‚  Combines: "my name AHMED help"              â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚              DISPLAY OUTPUT                   â”‚
              â”‚                                              â”‚
              â”‚  English: "my name AHMED help"               â”‚
              â”‚  Arabic:  "Ø§Ø³Ù…ÙŠ Ø£Ø­Ù…Ø¯ ÙŠØ³Ø§Ø¹Ø¯"                  â”‚
              â”‚  (via shared_word_vocabulary.csv translation) â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## How Mode Detection Works

The system needs to know **when to use letters vs. words**. Three approaches:

### Option A: Motion-Based (Recommended)
```python
# Track landmark movement between frames
movement = np.mean(np.abs(current_landmarks - previous_landmarks))

if movement > MOTION_THRESHOLD:
    mode = "WORD"      # hand is moving â†’ sign language word
    # Buffer 30 frames â†’ feed to BiLSTM
else:
    mode = "LETTER"    # hand is still â†’ fingerspelling
    # Feed single frame â†’ MLP
```

### Option B: Explicit Gesture Toggle
- User makes a specific "switch" gesture to toggle modes
- E.g., open palm = "I'm spelling now", fist = "I'm signing words"

### Option C: Run Both Models Simultaneously
```python
# Always run both models, use the more confident prediction
letter_conf = letter_model.predict(single_frame).max()
word_conf = word_model.predict(frame_buffer).max()

if word_conf > letter_conf and word_conf > 0.7:
    use word prediction
else:
    use letter prediction
```

---

## What Already Exists vs. What Needs Building

### âœ… Already Done (this repo)
| Component | Location | Status |
|---|---|---|
| Letter Model (ASL) | `Letters/ASL Letter (English)/` | âœ… Trained |
| Letter Model (ArSL) | `Letters/ArSL Letter (Arabic)/` | âœ… Trained |
| Word Model (ASL) | `Words/ASL Word (English)/` | âœ… Ready to train |
| Word Model (ArSL) | `Words/ArSL Word (Arabic)/` | â³ Needs KArSL data |
| Letter Stream Decoder | `Letters/Guides/letter_stream_decoder.py` | âœ… Built |
| Shared Vocabulary | `Words/Shared/shared_word_vocabulary.csv` | âœ… 157 words |
| Bilingual Translation | Via shared `word_id` | âœ… Built into vocab |

### ðŸ”¨ Needs Building (future Combined Notebook)
| Component | Description | Complexity |
|---|---|---|
| Mode Detector | Motion analysis to switch letterâ†”word | Medium |
| Frame Buffer | Rolling 30-frame window for word model | Easy |
| Sentence Builder | Combine letter + word predictions | Medium |
| Combined Webcam Loop | Single loop running both models | Medium |
| Arabic Display | RTL text rendering in OpenCV | Easy |

---

## Pseudocode: Combined Inference Loop

```python
# Load both models
letter_model = tf.keras.models.load_model('asl_mediapipe_mlp_model_best.h5')
word_model = tf.keras.models.load_model('asl_word_lstm_model_best.h5')

# Initialize
frame_buffer = deque(maxlen=30)  # rolling window for word model
sentence = ""
letter_decoder = LetterStreamDecoder()
prev_landmarks = None

while webcam.isOpened():
    frame = webcam.read()
    landmarks = mediapipe.extract(frame)  # shape: (63,)
    
    if landmarks is None:
        continue
    
    # Add to rolling buffer
    frame_buffer.append(landmarks)
    
    # Calculate hand movement
    if prev_landmarks is not None:
        movement = np.mean(np.abs(landmarks - prev_landmarks))
    else:
        movement = 0
    prev_landmarks = landmarks
    
    if movement > MOTION_THRESHOLD and len(frame_buffer) == 30:
        # === WORD MODE ===
        sequence = np.array(frame_buffer).reshape(1, 30, 63)
        word_pred = word_model.predict(sequence)
        word_conf = word_pred.max()
        
        if word_conf > 0.7:
            word_id = np.argmax(word_pred)
            word = vocab_df[vocab_df['word_id'] == word_id]['english'].values[0]
            sentence += word + " "
            frame_buffer.clear()  # reset after word detected
    else:
        # === LETTER MODE ===
        letter_pred = letter_model.predict(landmarks.reshape(1, -1))
        letter = label_encoder.inverse_transform([np.argmax(letter_pred)])[0]
        
        result = letter_decoder.feed(letter)
        if result:
            if result == 'SPACE':
                sentence += ' '
            elif result == 'DELETE':
                sentence = sentence[:-1]
            else:
                sentence += result
    
    # Display
    display(frame, sentence)
```

---

## Bilingual Example

```
User signs (ASL):           English output:    Arabic output:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
[word: "my"]                "my"               Ù„ÙŠ
[word: "name"]              "name"             Ø§Ø³Ù…
[letters: A-H-M-E-D]       "AHMED"            Ø£Ø­Ù…Ø¯
[word: "help"]              "help"             ÙŠØ³Ø§Ø¹Ø¯
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Final:                      "my name AHMED     "Ø§Ø³Ù…ÙŠ Ø£Ø­Ù…Ø¯ ÙŠØ³Ø§Ø¹Ø¯"
                             help"
```

The bilingual translation happens via the shared vocabulary:
- Word "help" â†’ `word_id=2` â†’ English: "help" / Arabic: "ÙŠØ³Ø§Ø¹Ø¯"
- Letters are displayed as-is (both alphabets supported)

---

## Summary

| Question | Answer |
|---|---|
| Can letters + words work together? | **Yes** â€” letters for spelling, words for common signs |
| How does it switch? | **Motion detection** â€” still hand = letter, moving = word |
| Can I spell "Ahmed"? | **Yes** â€” sign letters A-H-M-E-D, decoder builds "AHMED" |
| Can I sign "help" as one word? | **Yes** â€” word model recognizes it in one gesture |
| Does translation work? | **Yes** â€” shared word_id maps English â†” Arabic |
| What needs building? | **Combined notebook** with mode detection + sentence builder |
